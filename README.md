# TodoList IA - Backend Proxy

Ce serveur Node.js agit comme un proxy s√©curis√© et intelligent entre l'application front-end TodoList IA et l'API d'OpenAI. Son r√¥le est de prot√©ger la cl√© API et de centraliser la logique de construction des prompts.

### üöÄ √Ä propos du projet

L'objectif principal de ce backend est de cr√©er une couche de s√©curit√© et d'abstraction. En agissant comme interm√©diaire, il emp√™che l'exposition de la cl√© API d'OpenAI c√¥t√© client, un imp√©ratif de s√©curit√©. De plus, il centralise toute la logique de formatage des prompts envoy√©s √† l'IA, ce qui permet de maintenir un front-end plus l√©ger et de simplifier les futures mises √† jour de la logique d'IA.

### ‚ú® Responsabilit√©s Principales

- **S√©curisation de la Cl√© API :** La cl√© API d'OpenAI est stock√©e de mani√®re s√©curis√©e dans les variables d'environnement du serveur.
- **Gestion des CORS :** Autorise les requ√™tes provenant uniquement du domaine de l'application front-end pour une s√©curit√© accrue.
- **Proxy d'API :** Re√ßoit les demandes du front-end, construit la requ√™te appropri√©e pour l'API d'OpenAI, et relaie la r√©ponse.
- **Logique des Prompts :** Contient la logique pour formater les prompts envoy√©s √† l'IA pour diff√©rentes t√¢ches (g√©n√©ration de sous-t√¢ches, cat√©gorisation).

### üîå API Endpoint

Le serveur expose un unique endpoint pour toutes les interactions avec l'IA.

POST /api/openai

Cet endpoint accepte une requ√™te avec un corps JSON pour interagir avec l'API OpenAI.

Corps de la requ√™te (Request Body) :

JSON
{
  "type": "generateSubtasks" | "categorizeTask",
  "prompt": "Le texte de la t√¢che √† analyser",
  "model": "gpt-4o-mini",
  "max_tokens": 150,
  "temperature": 0.7
}

- **type** (requis) : Le type d'action √† effectuer.
- **prompt** (requis) : Le contenu textuel de la t√¢che.
- **model** : Param√®tres optionnels pour contr√¥ler le comportement de l'IA.
- **max_tokens** : Param√®tres optionnels pour contr√¥ler le comportement de l'IA.
- **temperature** : Param√®tres optionnels pour contr√¥ler le comportement de l'IA.

### R√©ponse (Response) :

- En cas de succ√®s, le serveur renvoie directement la r√©ponse JSON de l'API d'OpenAI.
- En cas d'erreur (cl√© API manquante, erreur de l'API OpenAI, etc.), il renvoie un objet JSON avec une cl√© error et potentiellement details.

### üõ†Ô∏è D√©pendances

- **xpress.js** : Framework web pour Node.js.
- **node-fetch** : Permet de faire des requ√™tes fetch c√¥t√© serveur.
- **cors** : Middleware pour g√©rer les requ√™tes Cross-Origin Resource Sharing.

### ‚öôÔ∏è Installation et Lancement Local

Clonez le d√©p√¥t :
```sh
git clone https://github.com/Aurelien-D/ToDoList-IA-BackEnd.git
```
Naviguez dans le dossier du projet :
```sh

cd ToDoList-IA-BackEnd
```
Installez les d√©pendances :
```sh

npm install
```
Configuration de l'environnement : Cr√©ez un fichier .env √† la racine du projet et ajoutez votre cl√© API OpenAI :
```sh
OPENAI_API_KEY=sk-VotreCleApiIci
```
Lancez le serveur :
```sh

npm start
```
Le serveur sera alors accessible √† l'adresse http://localhost:3001.

## üë®‚Äçüíª Auteur

- **Aur√©lien DUJEUX** - [Aurelien-D sur GitHub](https://github.com/Aurelien-D)