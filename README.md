TodoList IA - Backend Proxy
üéØ R√¥le du Projet
Ce serveur Node.js agit comme un proxy s√©curis√© entre l'application front-end TodoList IA et l'API d'OpenAI.

Son r√¥le principal est de prot√©ger la cl√© API d'OpenAI, qui ne doit jamais √™tre expos√©e c√¥t√© client. Il centralise √©galement la logique de construction des prompts envoy√©s √† l'IA.

‚ú® Responsabilit√©s Principales
S√©curisation de la Cl√© API : La cl√© API d'OpenAI est stock√©e de mani√®re s√©curis√©e dans les variables d'environnement du serveur.

Gestion des CORS : Autorise les requ√™tes provenant uniquement du domaine de l'application front-end.

Proxy d'API : Re√ßoit les demandes du front-end, construit la requ√™te appropri√©e pour l'API d'OpenAI, et relaie la r√©ponse.

Logique des Prompts : Contient la logique pour formater les prompts envoy√©s √† l'IA pour diff√©rentes t√¢ches (g√©n√©ration de sous-t√¢ches, cat√©gorisation).

üîå API Endpoint
Le serveur expose un unique endpoint pour toutes les interactions avec l'IA.

POST /api/openai
Cet endpoint accepte une requ√™te avec un corps JSON pour interagir avec l'API OpenAI.

Corps de la requ√™te (Request Body) :

{
  "type": "generateSubtasks" | "categorizeTask",
  "prompt": "Le texte de la t√¢che √† analyser",
  "model": "gpt-4o-mini",
  "max_tokens": 150,
  "temperature": 0.7
}

type (requis) : Le type d'action √† effectuer.

prompt (requis) : Le contenu textuel de la t√¢che.

model, max_tokens, temperature : Param√®tres optionnels pour contr√¥ler le comportement de l'IA.

R√©ponse (Response) :

En cas de succ√®s, le serveur renvoie directement la r√©ponse JSON de l'API d'OpenAI.

En cas d'erreur (cl√© API manquante, erreur de l'API OpenAI, etc.), il renvoie un objet JSON avec une cl√© error et potentiellement details.

‚öôÔ∏è Installation et Lancement Local
Clonez le d√©p√¥t :

git clone https://github.com/Aurelien-D/ToDoList-IA-BackEnd.git

Naviguez dans le dossier du projet :

cd ToDoList-IA-BackEnd

Installez les d√©pendances :

npm install

Configuration de l'environnement :
Cr√©ez un fichier .env √† la racine du projet et ajoutez votre cl√© API OpenAI :

OPENAI_API_KEY=sk-VotreCleApiIci

Lancez le serveur :

npm start

Le serveur sera alors accessible √† l'adresse http://localhost:3001.

üõ†Ô∏è D√©pendances
Express.js : Framework web pour Node.js.

node-fetch : Permet de faire des requ√™tes fetch c√¥t√© serveur.

cors : Middleware pour g√©rer les requ√™tes Cross-Origin Resource Sharing.

üë®‚Äçüíª Auteur
Aur√©lien DUJEUX - Aurelien-D sur GitHub